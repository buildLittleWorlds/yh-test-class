{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10: Portfolio Project Planning\n",
    "## Designing Your Fine-Tuning Project\n",
    "\n",
    "**Today's Goals:**\n",
    "1. Understand what fine-tuning is and why it's powerful\n",
    "2. Brainstorm project ideas\n",
    "3. Choose your project, dataset, and approach\n",
    "4. Create a project plan for weeks 11-12\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: What is Fine-Tuning?\n",
    "\n",
    "**Fine-tuning** = Taking a pre-trained model and teaching it something new.\n",
    "\n",
    "### Why Fine-Tune?\n",
    "\n",
    "Pre-trained models (like GPT-2, BERT) know a lot about language, but they don't know about YOUR specific task.\n",
    "\n",
    "**Example:**\n",
    "- GPT-2 knows how to write text\n",
    "- But it doesn't know YOUR company's writing style\n",
    "- Fine-tune it on YOUR data â†’ It writes like YOU want\n",
    "\n",
    "### The Analogy:\n",
    "\n",
    "| Stage | Human Analogy | AI Equivalent |\n",
    "|-------|--------------|---------------|\n",
    "| Pre-training | Going to school | Training on huge datasets |\n",
    "| Fine-tuning | Specialized job training | Training on YOUR data |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Not Train From Scratch?\n",
    "\n",
    "Training a model from scratch requires:\n",
    "- **Millions** of examples\n",
    "- **Days/weeks** of compute time\n",
    "- **Expensive** GPUs\n",
    "\n",
    "Fine-tuning requires:\n",
    "- **Hundreds to thousands** of examples\n",
    "- **Minutes to hours** of compute time\n",
    "- **Free Colab** can work!\n",
    "\n",
    "**This is why fine-tuning is so powerful!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: Project Ideas\n",
    "\n",
    "Here are some beginner-friendly fine-tuning projects:\n",
    "\n",
    "### Text Classification Projects\n",
    "\n",
    "| Project | Dataset | Description |\n",
    "|---------|---------|-------------|\n",
    "| Spam Detector | SMS Spam | Classify texts as spam or not spam |\n",
    "| Emotion Classifier | Emotion dataset | Detect emotions in text |\n",
    "| News Categorizer | AG News | Sort news into topics |\n",
    "| Sentiment Analyzer | IMDB/Rotten Tomatoes | Positive vs negative |\n",
    "\n",
    "### Text Generation Projects\n",
    "\n",
    "| Project | Dataset | Description |\n",
    "|---------|---------|-------------|\n",
    "| Story Writer | Custom stories | Generate stories in a specific style |\n",
    "| Chatbot Persona | Conversation data | Bot with a specific personality |\n",
    "| Code Explainer | Code + explanations | Explain code in plain English |\n",
    "\n",
    "### Other Ideas\n",
    "\n",
    "| Project | Type | Description |\n",
    "|---------|------|-------------|\n",
    "| Question Answerer | Q&A | Answer questions about a topic |\n",
    "| Summarizer | Summarization | Summarize specific types of text |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: What's Realistic for Free Colab?\n",
    "\n",
    "### Good choices (will work well):\n",
    "- Text classification (sentiment, spam, emotions)\n",
    "- Small text generation models (DistilGPT-2)\n",
    "- Small datasets (1,000 - 10,000 examples)\n",
    "\n",
    "### Challenging (might work with patience):\n",
    "- Larger models (GPT-2 medium)\n",
    "- Bigger datasets (50,000+ examples)\n",
    "\n",
    "### Probably too big for free Colab:\n",
    "- Large image models\n",
    "- Huge language models\n",
    "- Very large datasets\n",
    "\n",
    "**Recommendation: Start small!** You can always scale up later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 4: Choosing Your Project\n",
    "\n",
    "### Decision Framework:\n",
    "\n",
    "1. **What interests you?** (Pick something fun!)\n",
    "2. **What data is available?** (Check Hugging Face Datasets)\n",
    "3. **Is it doable in 2 weeks?** (Keep it simple)\n",
    "4. **Can you explain it?** (For your portfolio)\n",
    "\n",
    "### Recommended Starter Projects:\n",
    "\n",
    "**Option A: Emotion Classifier**\n",
    "- Dataset: `emotion`\n",
    "- Model: DistilBERT\n",
    "- Task: Classify text into 6 emotions\n",
    "- Difficulty: â­â­ (Good first project)\n",
    "\n",
    "**Option B: Sentiment Analyzer**\n",
    "- Dataset: `rotten_tomatoes` (smaller) or `imdb`\n",
    "- Model: DistilBERT\n",
    "- Task: Positive vs negative classification\n",
    "- Difficulty: â­ (Easiest)\n",
    "\n",
    "**Option C: Text Generator**\n",
    "- Dataset: Custom or existing\n",
    "- Model: DistilGPT-2\n",
    "- Task: Generate text in a specific style\n",
    "- Difficulty: â­â­â­ (More challenging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 5: Project Planning Worksheet\n",
    "\n",
    "Fill this out to plan your project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Project Plan\n",
    "\n",
    "**Project Name:** _________________________________\n",
    "\n",
    "**What it does:** \n",
    "_________________________________\n",
    "_________________________________\n",
    "\n",
    "**Dataset:** \n",
    "- Name: _________________________________\n",
    "- Size: _____________ examples\n",
    "- Source: Hugging Face / Custom / Other\n",
    "\n",
    "**Base Model:** \n",
    "- [ ] DistilBERT (text classification)\n",
    "- [ ] DistilGPT-2 (text generation)\n",
    "- [ ] Other: _________________\n",
    "\n",
    "**Why I chose this project:**\n",
    "_________________________________\n",
    "_________________________________\n",
    "\n",
    "**How I'll know it works:**\n",
    "_________________________________\n",
    "_________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 6: Let's Explore Your Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "!pip install datasets transformers -q\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your chosen dataset\n",
    "# Change this to your dataset!\n",
    "\n",
    "DATASET_NAME = \"emotion\"  # Change this!\n",
    "\n",
    "dataset = load_dataset(DATASET_NAME)\n",
    "\n",
    "print(f\"\\nDataset: {DATASET_NAME}\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Show structure\n",
    "for split in dataset.keys():\n",
    "    print(f\"{split}: {len(dataset[split])} examples\")\n",
    "\n",
    "print(f\"\\nColumns: {dataset['train'].column_names}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at examples\n",
    "print(\"Sample examples:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for i in range(5):\n",
    "    ex = dataset['train'][i]\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    for key, value in ex.items():\n",
    "        if isinstance(value, str) and len(value) > 100:\n",
    "            print(f\"  {key}: {value[:100]}...\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check label distribution\n",
    "df = pd.DataFrame(dataset['train'])\n",
    "\n",
    "if 'label' in df.columns:\n",
    "    print(\"Label distribution:\")\n",
    "    print(df['label'].value_counts())\n",
    "    \n",
    "    # Check balance\n",
    "    counts = df['label'].value_counts()\n",
    "    max_diff = (counts.max() - counts.min()) / counts.max()\n",
    "    if max_diff < 0.2:\n",
    "        print(\"\\nâœ… Dataset is well-balanced!\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Dataset is imbalanced (max difference: {max_diff:.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 7: Week 11-12 Timeline\n",
    "\n",
    "Here's what we'll do in the next two weeks:\n",
    "\n",
    "### Week 11: Fine-Tuning Workshop\n",
    "1. Set up the training environment\n",
    "2. Prepare the dataset\n",
    "3. Configure the model\n",
    "4. Run training (with AI help for the code!)\n",
    "5. Save your fine-tuned model\n",
    "\n",
    "### Week 12: Showcase\n",
    "1. Test your model thoroughly\n",
    "2. Create a demo\n",
    "3. Push everything to GitHub\n",
    "4. Present your project!\n",
    "5. Celebrate! ðŸŽ‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 8: Prepare for Next Week\n",
    "\n",
    "### Homework (Required!):\n",
    "\n",
    "1. **Decide on your project** - Fill out the planning worksheet above\n",
    "2. **Explore your dataset** - Run the code above with your chosen dataset\n",
    "3. **Think about success criteria** - How will you know if your model works?\n",
    "\n",
    "### Questions to Answer:\n",
    "\n",
    "1. What problem am I solving?\n",
    "2. What data will I use?\n",
    "3. What model will I fine-tune?\n",
    "4. How will I test if it works?\n",
    "5. What will I show in my presentation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Project Ideas Quick Reference\n",
    "\n",
    "### Easiest (Recommended for first project):\n",
    "\n",
    "```python\n",
    "# Sentiment Classification\n",
    "dataset = load_dataset(\"rotten_tomatoes\")  # Small, fast\n",
    "model = \"distilbert-base-uncased\"\n",
    "```\n",
    "\n",
    "### Intermediate:\n",
    "\n",
    "```python\n",
    "# Emotion Classification (6 classes)\n",
    "dataset = load_dataset(\"emotion\")\n",
    "model = \"distilbert-base-uncased\"\n",
    "```\n",
    "\n",
    "### More Challenging:\n",
    "\n",
    "```python\n",
    "# Text Generation\n",
    "dataset = load_dataset(\"your_custom_dataset\")\n",
    "model = \"distilgpt2\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Checklist: What You Learned Today\n",
    "\n",
    "- [ ] What fine-tuning is (teaching pre-trained models new things)\n",
    "- [ ] Why fine-tuning is better than training from scratch\n",
    "- [ ] What projects are realistic for free Colab\n",
    "- [ ] How to choose a project (interest + data + feasibility)\n",
    "- [ ] Your project plan for weeks 11-12\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking Ahead: Week 11\n",
    "\n",
    "Next week we'll actually fine-tune your model!\n",
    "\n",
    "**Come prepared with:**\n",
    "1. Your chosen dataset loaded and explored\n",
    "2. A clear idea of what you're building\n",
    "3. Questions about anything you're unsure about\n",
    "\n",
    "**What we'll cover:**\n",
    "- Setting up training with Hugging Face Trainer\n",
    "- Running fine-tuning on free Colab\n",
    "- Saving and loading your fine-tuned model\n",
    "\n",
    "---\n",
    "\n",
    "*Youth Horizons AI Researcher Program - Level 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Bonus: Preview of Fine-Tuning Code\n",
    "\n",
    "Here's a sneak peek at what we'll do next week. Don't worry about understanding it all yet - we'll go through it step by step!\n",
    "\n",
    "```python\n",
    "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "# Load model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2  # Binary classification\n",
    ")\n",
    "\n",
    "# Training settings\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./my-model\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    ")\n",
    "\n",
    "# Train!\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=test_data,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "```\n",
    "\n",
    "It's simpler than you might think!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
